{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00da3d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from geobr import read_state, read_municipality\n",
    "from matplotlib.colors import LogNorm\n",
    "import unicodedata\n",
    "import os\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad162c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_log_custom(coluna):\n",
    "    \"\"\"\n",
    "    Normaliza uma coluna usando a escala logarítmica customizada:\n",
    "    log(x + 1) / log(max(x) + 1)\n",
    "    \"\"\"\n",
    "    # Adiciona +1 para evitar log(0)\n",
    "    coluna_log = np.log(coluna + 1)\n",
    "    # Pega o log do valor máximo (também +1)\n",
    "    max_log = np.log(coluna.max() + 1)\n",
    "    \n",
    "    # Evita divisão por zero se o max_log for 0\n",
    "    if max_log == 0:\n",
    "        return pd.Series(0, index=coluna.index)\n",
    "        \n",
    "    return coluna_log / max_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7603bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o shapefile de SP (apenas uma vez)\n",
    "try:\n",
    "    mun_sp = read_municipality(code_muni=\"SP\", year=2020)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar dados do geobr: {e}. Certifique-se de ter conexão com a internet.\")\n",
    "    # Fallback ou tratamento de erro\n",
    "\n",
    "def normalizar_string(text):\n",
    "    \"\"\"Remove acentos e converte para minúsculas.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode(\"utf-8\").lower()\n",
    "    return text\n",
    "\n",
    "# Adiciona coluna normalizada no geodataframe\n",
    "mun_sp[\"name_norm\"] = mun_sp[\"name_muni\"].apply(normalizar_string)\n",
    "\n",
    "def plot_choropleth_ranking(df_ranking, coluna_cidade, coluna_score, titulo_mapa, destacar_top=5, escala_log=False):\n",
    "    \"\"\"\n",
    "    Plota um mapa coroplético do estado de SP com base em um score.\n",
    "    (Versão modificada para aceitar um título)\n",
    "    \"\"\"\n",
    "    # Normaliza os nomes para o merge\n",
    "    df_ranking[\"name_norm\"] = df_ranking[coluna_cidade].apply(normalizar_string)\n",
    "\n",
    "    # Junta geodados com ranking\n",
    "    gdf = mun_sp.merge(df_ranking, on=\"name_norm\", how=\"left\")\n",
    "\n",
    "    # Garante que não tenha zero se for usar log\n",
    "    gdf[coluna_score] = gdf[coluna_score].fillna(0)\n",
    "    if escala_log:\n",
    "        gdf[coluna_score] = gdf[coluna_score].replace(0, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "    # Define estilo do mapa\n",
    "    norm = LogNorm(vmin=gdf[coluna_score].min(), vmax=gdf[coluna_score].max()) if escala_log else None\n",
    "    legenda_label = f\"{coluna_score} (escala log)\" if escala_log else coluna_score\n",
    "\n",
    "    # Desenha o mapa\n",
    "    gdf.plot(\n",
    "        column=coluna_score,\n",
    "        cmap=\"OrRd\",\n",
    "        linewidth=0,\n",
    "        ax=ax,\n",
    "        norm=norm,\n",
    "        legend=True,\n",
    "        legend_kwds={\"label\": legenda_label}\n",
    "    )\n",
    "\n",
    "    # Borda do estado\n",
    "    read_state(\"SP\", year=2020).plot(ax=ax, facecolor=\"none\", edgecolor=\"black\", linewidth=2)\n",
    "\n",
    "    # Destaca top municípios\n",
    "    if destacar_top > 0:\n",
    "        top = gdf.nlargest(destacar_top, coluna_score)\n",
    "        top.plot(ax=ax, facecolor=\"none\", edgecolor=\"black\", linewidth=2)\n",
    "\n",
    "        # Labels\n",
    "        print(f\"--- Top {destacar_top} Cidades (Score: {coluna_score}) ---\")\n",
    "        for _, row in top.iterrows():\n",
    "            c = row.geometry.centroid\n",
    "            print(f\"{row[coluna_cidade]} (Score: {row[coluna_score]:.4f})\")\n",
    "\n",
    "    ax.set_title(titulo_mapa, fontsize=16)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    # Salvar a figura em vez de mostrar\n",
    "    plt.savefig(f\"{titulo_mapa.replace(' ', '_').replace('(', '').replace(')', '')}.png\", bbox_inches='tight')\n",
    "    plt.close(fig) # Fecha a figura para economizar memória\n",
    "    print(f\"Mapa salvo como: {titulo_mapa.replace(' ', '_').replace('(', '').replace(')', '')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b56589d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos CSV de dimensões carregados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Definindo o caminho base\n",
    "DATA_PATH = './dados/exportados/' # Assumindo que os arquivos estão na raiz ou em subpastas\n",
    "\n",
    "# Verificando os caminhos corretos\n",
    "# (Usando os nomes dos arquivos que você forneceu)\n",
    "path_pop = DATA_PATH + 'DimPopulacao.csv'\n",
    "path_farm = DATA_PATH + 'DimContagemFarmacias.csv'\n",
    "path_pib = DATA_PATH + 'DimPIB.csv'\n",
    "path_cidade = DATA_PATH + 'DimCidadePotencial.csv'\n",
    "path_pesos = DATA_PATH + 'DimPesoFaixaEtaria.csv'\n",
    "\n",
    "# Carregar dados das dimensões\n",
    "try:\n",
    "    DimPopulacao = pd.read_csv(path_pop, sep=';')\n",
    "    DimContagemFarmacias = pd.read_csv(path_farm, sep=';')\n",
    "    DimPIB = pd.read_csv(path_pib, sep=';')\n",
    "    DimCidadePotencial = pd.read_csv(path_cidade, sep=';')\n",
    "    DimPesoFaixaEtaria = pd.read_csv(path_pesos, sep=';')\n",
    "    \n",
    "    print(\"Arquivos CSV de dimensões carregados com sucesso.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Erro: Arquivo não encontrado. Verifique o caminho: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af1ad4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de População e PIB pré-processados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Pré-processar População\n",
    "# Calcula População Total por cidade\n",
    "pop_total_por_cidade = DimPopulacao.groupby('codigoibge')['contagempop'].transform('sum')\n",
    "DimPopulacao['PopTotal'] = pop_total_por_cidade\n",
    "\n",
    "# Filtra cidades (ex: > 99k habitantes)\n",
    "df_pop_filtrado = DimPopulacao[DimPopulacao['PopTotal'] > 99000].copy()\n",
    "\n",
    "# Renomeia colunas para o merge com a tabela de pesos (MUITO IMPORTANTE)\n",
    "df_pop_pronto = df_pop_filtrado.rename(columns={\n",
    "    'faixaetariapop': 'faixaetaria',\n",
    "    'sexopop': 'sexofaixaetaria'\n",
    "})\n",
    "# Seleciona colunas úteis\n",
    "df_pop_pronto = df_pop_pronto[['codigoibge', 'contagempop', 'faixaetaria', 'sexofaixaetaria', 'PopTotal']]\n",
    "\n",
    "\n",
    "# 2. Pré-processar PIB\n",
    "df_pib_pronto = DimPIB[\n",
    "    (DimPIB['setorpib'] == 'Comércio e Serviços') & \n",
    "    (DimPIB['anopib'] == 2021)\n",
    "][['codigoibge', 'valorpib']]\n",
    "\n",
    "print(\"Dados de População e PIB pré-processados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4568f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontradas 3 estimativas: ['Uso de medicamentos (Doenças Crônicas)' 'Prioridade Idosos (60+)'\n",
      " 'Peso Uniforme (Todos)']\n",
      "\n",
      "--- Iniciando Cálculo para: Uso de medicamentos (Doenças Crônicas) ---\n",
      "\n",
      "--- Top 5 Cidades para 'Uso de medicamentos (Doenças Crônicas)' ---\n",
      "      nomecidadepotencial  score_final_norm  score_pop_norm  \\\n",
      "66              São Paulo          1.000000        1.000000   \n",
      "45                 Osasco          0.994431        0.860407   \n",
      "17                Cubatão          0.992930        0.765317   \n",
      "47               Paulínia          0.992070        0.766140   \n",
      "61  São Bernardo do Campo          0.990114        0.867845   \n",
      "\n",
      "    score_saturacao_norm  score_pib_norm  PopTotal  qtdfarmacias  \n",
      "66              0.981424        0.906530  11451999          4887  \n",
      "45              0.978356        0.950019    728615           310  \n",
      "17              0.999651        0.913072    112476            36  \n",
      "47              0.973068        1.000000    110537            50  \n",
      "61              0.988068        0.883688    810729           321  \n",
      "--- Top 10 Cidades (Score: score_final_norm) ---\n",
      "São Paulo (Score: 1.0000)\n",
      "Osasco (Score: 0.9944)\n",
      "Cubatão (Score: 0.9929)\n",
      "Paulínia (Score: 0.9921)\n",
      "São Bernardo do Campo (Score: 0.9901)\n",
      "Santos (Score: 0.9891)\n",
      "Itapevi (Score: 0.9888)\n",
      "Jacareí (Score: 0.9879)\n",
      "Guarulhos (Score: 0.9861)\n",
      "Diadema (Score: 0.9859)\n",
      "Mapa salvo como: Ranking_Final_-_Uso_de_medicamentos_Doenças_Crônicas.png\n",
      "\n",
      "--- Iniciando Cálculo para: Prioridade Idosos (60+) ---\n",
      "\n",
      "--- Top 5 Cidades para 'Prioridade Idosos (60+)' ---\n",
      "      nomecidadepotencial  score_final_norm  score_pop_norm  \\\n",
      "60                 Santos          1.000000        0.838709   \n",
      "66              São Paulo          0.992834        1.000000   \n",
      "61  São Bernardo do Campo          0.977423        0.846910   \n",
      "36                Jacareí          0.976264        0.778212   \n",
      "45                 Osasco          0.975470        0.833652   \n",
      "\n",
      "    score_saturacao_norm  score_pib_norm  PopTotal  qtdfarmacias  \n",
      "60              1.000000        0.886150    418608           183  \n",
      "66              0.957646        0.906530  11451999          4887  \n",
      "61              0.957255        0.883688    810729           321  \n",
      "36              0.971762        0.859720    240275            82  \n",
      "45              0.936570        0.950019    728615           310  \n",
      "--- Top 10 Cidades (Score: score_final_norm) ---\n",
      "Santos (Score: 1.0000)\n",
      "São Paulo (Score: 0.9928)\n",
      "São Bernardo do Campo (Score: 0.9774)\n",
      "Jacareí (Score: 0.9763)\n",
      "Osasco (Score: 0.9755)\n",
      "Santo André (Score: 0.9739)\n",
      "Jundiaí (Score: 0.9735)\n",
      "São Caetano do Sul (Score: 0.9733)\n",
      "Campinas (Score: 0.9717)\n",
      "Ribeirão Preto (Score: 0.9710)\n",
      "Mapa salvo como: Ranking_Final_-_Prioridade_Idosos_60+.png\n",
      "\n",
      "--- Iniciando Cálculo para: Peso Uniforme (Todos) ---\n",
      "\n",
      "--- Top 5 Cidades para 'Peso Uniforme (Todos)' ---\n",
      "   nomecidadepotencial  score_final_norm  score_pop_norm  \\\n",
      "66           São Paulo          1.000000        1.000000   \n",
      "32             Itapevi          0.998584        0.760184   \n",
      "17             Cubatão          0.998264        0.715562   \n",
      "45              Osasco          0.993869        0.830514   \n",
      "18             Diadema          0.990822        0.792570   \n",
      "\n",
      "    score_saturacao_norm  score_pib_norm  PopTotal  qtdfarmacias  \n",
      "66              0.958777        0.906530  11451999          4887  \n",
      "32              1.000000        0.872912    232297            71  \n",
      "17              0.994304        0.913072    112476            36  \n",
      "45              0.959146        0.950019    728615           310  \n",
      "18              0.992224        0.833420    393237           128  \n",
      "--- Top 10 Cidades (Score: score_final_norm) ---\n",
      "São Paulo (Score: 1.0000)\n",
      "Itapevi (Score: 0.9986)\n",
      "Cubatão (Score: 0.9983)\n",
      "Osasco (Score: 0.9939)\n",
      "Diadema (Score: 0.9908)\n",
      "Jacareí (Score: 0.9894)\n",
      "São Bernardo do Campo (Score: 0.9889)\n",
      "Guarulhos (Score: 0.9888)\n",
      "Paulínia (Score: 0.9886)\n",
      "Santana de Parnaíba (Score: 0.9883)\n",
      "Mapa salvo como: Ranking_Final_-_Peso_Uniforme_Todos.png\n",
      "\n",
      "--- Processo concluído ---\n",
      "Todos os mapas de estimativa foram gerados e salvos em arquivos .png.\n",
      "Os DataFrames do Top 5 para cada estimativa foram exibidos no console.\n"
     ]
    }
   ],
   "source": [
    "# 1. Pega a lista de estimativas únicas\n",
    "lista_estimativas = DimPesoFaixaEtaria['nomeestimativa'].unique()\n",
    "print(f\"Encontradas {len(lista_estimativas)} estimativas: {lista_estimativas}\")\n",
    "\n",
    "# 2. Loop principal\n",
    "for estimativa in lista_estimativas:\n",
    "    print(f\"\\n--- Iniciando Cálculo para: {estimativa} ---\")\n",
    "    \n",
    "    # --- Passo A: Filtrar Pesos da Estimativa Atual ---\n",
    "    df_pesos_atual = DimPesoFaixaEtaria[\n",
    "        DimPesoFaixaEtaria['nomeestimativa'] == estimativa\n",
    "    ][['faixaetaria', 'sexofaixaetaria', 'valorpeso']]\n",
    "    \n",
    "    # --- Passo B: Calcular Score Ponderado (com MERGE) ---\n",
    "    df_pop_ponderado = pd.merge(\n",
    "        df_pop_pronto,\n",
    "        df_pesos_atual,\n",
    "        on=['faixaetaria', 'sexofaixaetaria'],\n",
    "        how='inner' \n",
    "    )\n",
    "    df_pop_ponderado['score_ponderado_linha'] = df_pop_ponderado['contagempop'] * df_pop_ponderado['valorpeso']\n",
    "    \n",
    "    # --- Passo C: Agregar Score de População por Cidade ---\n",
    "    df_score_pop_agg = df_pop_ponderado.groupby('codigoibge').agg(\n",
    "        score_pop_raw=('score_ponderado_linha', 'sum'),\n",
    "        PopTotal=('PopTotal', 'first')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # --- Passo D: Montar Tabela Final (FatoScore) ---\n",
    "    df_final = df_score_pop_agg.merge(\n",
    "        DimCidadePotencial[['codigoibge', 'nomecidadepotencial']],\n",
    "        on='codigoibge',\n",
    "        how='left'\n",
    "    ).merge(\n",
    "        DimContagemFarmacias[['codigoibge', 'qtdfarmacias']],\n",
    "        on='codigoibge',\n",
    "        how='left'\n",
    "    ).merge(\n",
    "        df_pib_pronto,\n",
    "        on='codigoibge',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    df_final['qtdfarmacias'] = df_final['qtdfarmacias'].fillna(0)\n",
    "    df_final['valorpib'] = df_final['valorpib'].fillna(0)\n",
    "    \n",
    "    # --- Passo E: Calcular Scores (Saturação e PIB) ---\n",
    "    df_final[\"score_saturacao_raw\"] = df_final.apply(\n",
    "        lambda r: r[\"score_pop_raw\"] if r[\"qtdfarmacias\"] == 0 else r[\"score_pop_raw\"] / r[\"qtdfarmacias\"],\n",
    "        axis=1\n",
    "    )\n",
    "    df_final[\"score_pib_raw\"] = df_final.apply(\n",
    "        lambda r: 0 if r[\"PopTotal\"] == 0 else r[\"valorpib\"] / r[\"PopTotal\"],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # --- Passo F: Normalizar e Calcular Score Final ---\n",
    "    df_final[\"score_pop_norm\"] = normalizar_log_custom(df_final[\"score_pop_raw\"])\n",
    "    df_final[\"score_saturacao_norm\"] = normalizar_log_custom(df_final[\"score_saturacao_raw\"])\n",
    "    df_final[\"score_pib_norm\"] = normalizar_log_custom(df_final[\"score_pib_raw\"])\n",
    "\n",
    "    peso_pop = 1/10\n",
    "    peso_saturacao = 7/10\n",
    "    peso_pib = 2/10\n",
    "\n",
    "    df_final[\"score_final\"] = (\n",
    "        df_final[\"score_pop_norm\"] * peso_pop +\n",
    "        df_final[\"score_saturacao_norm\"] * peso_saturacao +\n",
    "        df_final[\"score_pib_norm\"] * peso_pib\n",
    "    )\n",
    "    df_final[\"score_final_norm\"] = normalizar_log_custom(df_final[\"score_final\"])\n",
    "    \n",
    "    # --- Passo G: Ordenar, Printar (NOVO) e Plotar ---\n",
    "    df_ranking_final = df_final.sort_values(\"score_final_norm\", ascending=False)\n",
    "    \n",
    "    print(f\"\\n--- Top 5 Cidades para '{estimativa}' ---\")\n",
    "    \n",
    "    # ----> MUDANÇA AQUI <----\n",
    "    # Printando as colunas mais relevantes do top 5\n",
    "    print(df_ranking_final[\n",
    "        [\n",
    "            'nomecidadepotencial', \n",
    "            'score_final_norm', \n",
    "            'score_pop_norm', \n",
    "            'score_saturacao_norm', \n",
    "            'score_pib_norm',\n",
    "            'PopTotal',\n",
    "            'qtdfarmacias'\n",
    "        ]\n",
    "    ].head())\n",
    "    \n",
    "    # Gerar o plot\n",
    "    plot_choropleth_ranking(\n",
    "        df_ranking_final,\n",
    "        coluna_cidade='nomecidadepotencial',\n",
    "        coluna_score='score_final_norm',\n",
    "        titulo_mapa=f\"Ranking Final - {estimativa}\",\n",
    "        destacar_top=10 # O plot ainda destaca 10 no mapa\n",
    "    )\n",
    "\n",
    "print(\"\\n--- Processo concluído ---\")\n",
    "print(\"Todos os mapas de estimativa foram gerados e salvos em arquivos .png.\")\n",
    "print(\"Os DataFrames do Top 5 para cada estimativa foram exibidos no console.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98f4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
